{"cells":[{"cell_type":"markdown","metadata":{"id":"AyPbJlzoyA5N"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Linear Classification\n","\n"," Implement Linear Classification using pytorch. This consists of having fully connected layers connected one after the other and ReLu activation functions between them.\n"," \n"," Build a neural network with a minimun of 2 layers in order to do classification."]},{"cell_type":"markdown","metadata":{"id":"Stm2Nhxlso2r"},"source":["Permit the notebook to access your drive"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ESXccfIu1H7u"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"whJSL42iyA5S"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7fecd6fc2ef0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import numpy as np\n","import torch.utils.data as utils\n","import time\n","import pdb\n","from torch.utils.data.sampler import SubsetRandomSampler\n","%matplotlib inline\n","\n","torch.manual_seed(1)    # reproducible"]},{"cell_type":"markdown","metadata":{"id":"zeTqh7pgs0JA"},"source":["Get the dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"zahsf3gOyA5U"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","X.shape = (9, 32, 32, 3)\n"]}],"source":["def get_train_valid_loader(data_dir='../data',\n","                           batch_size=64,\n","                           augment=False,\n","                           random_seed = 1,\n","                           valid_size=0.02,\n","                           shuffle=True,\n","                           show_sample=False,\n","                           num_workers=4,\n","                           pin_memory=False):\n","    \"\"\"\n","    Utility function for loading and returning train and valid\n","    multi-process iterators over the CIFAR-10 dataset. A sample\n","    9x9 grid of the images can be optionally displayed.\n","    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n","    Params\n","    ------\n","    - data_dir: path directory to the dataset.\n","    - batch_size: how many samples per batch to load.\n","    - augment: whether to apply the data augmentation scheme\n","      mentioned in the paper. Only applied on the train split.\n","    - random_seed: fix seed for reproducibility.\n","    - valid_size: percentage split of the training set used for\n","      the validation set. Should be a float in the range [0, 1].\n","    - shuffle: whether to shuffle the train/validation indices.\n","    - show_sample: plot 9x9 sample grid of the dataset.\n","    - num_workers: number of subprocesses to use when loading the dataset.\n","    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n","      True if using GPU.\n","    Returns\n","    -------\n","    - train_loader: training set iterator.\n","    - valid_loader: validation set iterator.\n","    \"\"\"\n","    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n","    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n","\n","    normalize = transforms.Normalize(\n","        mean=[0.4914, 0.4822, 0.4465],\n","        std=[0.2023, 0.1994, 0.2010],\n","    )\n","\n","    # define transforms\n","    valid_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            normalize,\n","    ])\n","    if augment:\n","        train_transform = transforms.Compose([\n","            transforms.RandomCrop(32, padding=4),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","    else:\n","        train_transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            normalize,\n","        ])\n","\n","    # load the dataset\n","    train_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=train_transform,\n","    )\n","\n","    valid_dataset = datasets.CIFAR10(\n","        root=data_dir, train=True,\n","        download=True, transform=valid_transform,\n","    )\n","\n","    num_train = len(train_dataset)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","\n","    if shuffle:\n","        np.random.seed(random_seed)\n","        np.random.shuffle(indices)\n","\n","    train_idx, valid_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=batch_size, sampler=train_sampler,\n","        num_workers=num_workers, pin_memory=pin_memory,\n","    )\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n","        num_workers=num_workers, pin_memory=pin_memory,\n","    )\n","\n","    # visualize some images\n","    if show_sample:\n","        sample_loader = torch.utils.data.DataLoader(\n","            train_dataset, batch_size=9, shuffle=shuffle,\n","            num_workers=num_workers, pin_memory=pin_memory,\n","        )\n","        data_iter = iter(sample_loader)\n","        images, labels = next(data_iter)\n","        X = images.numpy().transpose([0, 2, 3, 1])\n","        print(f\"X.shape = {X.shape}\")\n","        #plot_images(X, labels)\n","\n","    return (train_loader, valid_loader)\n","\n","trainloader, valloader = get_train_valid_loader(show_sample=True)"]},{"cell_type":"markdown","metadata":{"id":"dr58pZjGs3fF"},"source":["Define the network"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OYHld_YfyA5Z"},"outputs":[],"source":["class Net(torch.nn.Module):\n","    def __init__(self, n_feature, n_hidden, n_output):\n","        super(Net, self).__init__()\n","        \n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Define 2 or more different layers of the neural network                      #\n","        ################################################################################\n","\n","        self.fc1 = torch.nn.Linear(n_feature, n_hidden)\n","        self.fc2 = torch.nn.Linear(n_hidden, n_output)\n","\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0),-1)\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Set up the forward pass that the input data will go through.                 #\n","        # A good activation function betweent the layers is a ReLu function.           #\n","        ################################################################################\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","        return x"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"E0ynI2OZyA5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Net(\n","  (fc1): Linear(in_features=3072, out_features=2000, bias=True)\n","  (fc2): Linear(in_features=2000, out_features=1, bias=True)\n",")\n"]}],"source":["################################################################################\n","# TODO:                                                                        #\n","# Define the parameters of the network the way you want it to be.              #\n","# Choose an Optimizer that will be used to minimize the loss function.         #\n","################################################################################\n","net = Net(n_feature=3072, n_hidden=2000, n_output=1)     # define the network\n","print(net)  # net architecture\n","\n","# Loss and Optimizer (Try different learning rates)\n","# Softmax is internally computed.\n","# Set parameters to be updated. \n","\n","#optimizer = ........  # Choose the optimizer you want and tune its hyperparameter\n","optimizer = torch.optim.SGD(net.parameters(), lr=0.01) #, momentum=0.9)\n","loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n","################################################################################\n","#                              END OF YOUR CODE                                #\n","################################################################################"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"FBUs_zOVyA5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 3, 32, 32])\n","torch.Size([64, 1])\n","torch.Size([64])\n"]},{"ename":"IndexError","evalue":"Target 2 is out of bounds.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [25], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#loss.backward()\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3052\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: Target 2 is out of bounds."]}],"source":["#traindataset = utils.TensorDataset(X_train, y_train)\n","#trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n","\n","epochs = 10\n","steps = 0\n","print_every = 20\n","for e in range(epochs):\n","    start = time.time()\n","    for images, labels in iter(trainloader):\n","        steps += 1\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Run the training process                                                     #\n","        #                                                                              #\n","        ################################################################################\n","        optimizer.zero_grad()\n","        print(images.shape)\n","        output = net(images)\n","        print(output.shape)\n","        print(labels.shape)\n","        print(loss_func(output, labels))\n","        #loss.backward()\n","        optimizer.step()\n","    \n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","    \n","        if steps % print_every == 0:\n","                stop = time.time()\n","                # Test accuracy\n","                net.eval()\n","                correct = 0\n","                total = 0\n","                with torch.no_grad():\n","                    for data in valloader:\n","                          images, labels = data\n","                          outputs = net(images)\n","                          _, predicted = torch.max(F.softmax(outputs).data, 1)\n","                          total += labels.size(0)\n","                          correct += (predicted == labels).sum().item()\n","\n","                    print('Accuracy of the network on the %d val images: \\\n","                    %d %%' % (total,100 * correct / total))\n","\n","                start = time.time()"]},{"cell_type":"markdown","metadata":{"id":"7gx02lf4yA5c"},"source":["After training, the model should be saved to be tested on the test dataset or to be used in a real-life application. To save your model in pytorch:"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"cTzmX0nZyA5c"},"outputs":[],"source":["#torch.save(net.state_dict(), 'drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt')\n","torch.save(net.state_dict(), './linearClassifier_pytorch.ckpt')"]},{"cell_type":"markdown","metadata":{"id":"JdGRq6H7yA5d"},"source":["Remeber the above path. You need to load your trained model in another notebook:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Y0q1qkYsyA5e"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["#checkpoint = torch.load(\"drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt\")\n","checkpoint = torch.load(\"./linearClassifier_pytorch.ckpt\")\n","net.load_state_dict(checkpoint)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Linear Classification pytorch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"},"nteract":{"version":"0.12.3"}},"nbformat":4,"nbformat_minor":0}
