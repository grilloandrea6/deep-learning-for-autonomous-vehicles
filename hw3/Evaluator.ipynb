{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"aEW8FsaTRaOo"},"outputs":[],"source":["import numpy as np\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","import torch.utils.data as utils\n","from torchvision import datasets, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import os\n","import platform\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJAZFldDTQRz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"dtBf2_UXTPVs"},"outputs":[],"source":["#!rm -r DLAV-2024\n","#!git clone https://github.com/vita-epfl/DLAV-2024.git\n","path = os.getcwd() + '/../../DLAV-2024/homeworks/hw2/test_batch'"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"QEIcPZ4hT7fY"},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self, n_input_channels=3, n_output=10):\n","        super().__init__()\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Define 2 or more different layers of the neural network                      #\n","        ################################################################################\n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(in_channels=n_input_channels, out_channels=16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n","        \n","        # Define max pooling layer\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        \n","        # Define fully connected layers\n","        self.fc1 = nn.Linear(32 * 8 * 8, 128)  # Assuming input image size is 32x32 after two max pooling layers\n","        self.fc2 = nn.Linear(128, n_output)\n","        \n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","    \n","    def forward(self, x):\n","        ################################################################################\n","        # TODO:                                                                        #\n","        # Set up the forward pass that the input data will go through.                 #\n","        # A good activation function betweent the layers is a ReLu function.           #\n","        #                                                                              #\n","        # Note that the output of the last convolution layer should be flattened       #\n","        # before being inputted to the fully connected layer. We can flatten           #\n","        # Tensor `x` with `x.view`.                                                    #\n","        ################################################################################\n","        # First convolutional layer with ReLU activation and max pooling\n","        x = self.pool(F.relu(self.conv1(x)))\n","        \n","        # Second convolutional layer with ReLU activation and max pooling\n","        x = self.pool(F.relu(self.conv2(x)))\n","        \n","        # Flatten the output for fully connected layers\n","        x = x.view(-1, 32 * 8 * 8)\n","        \n","        # First fully connected layer with ReLU activation\n","        x = F.relu(self.fc1(x))\n","        \n","        # Second fully connected layer\n","        x = self.fc2(x)\n","        \n","        ################################################################################\n","        #                              END OF YOUR CODE                                #\n","        ################################################################################\n","        \n","        return x\n","    \n","    def predict(self, x):\n","        logits = self.forward(x)\n","        return F.softmax(logits,dim=1)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"p5v7OgpDR4m2"},"outputs":[],"source":["def predict_usingCNN(X,model_path):\n","    #########################################################################\n","    # TODO:                                                                 #\n","    # - Load your saved model                                               #\n","    # - Do the operation required to get the predictions                    #\n","    # - Return predictions in a numpy array                                 #\n","    # Note: For the predictions, you have to return the index of the max    #\n","    # value                                                                 #\n","    #########################################################################\n","    net = ConvNet()\n","\n","    net.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n","\n","    y_pred = net.predict(X).data.max(1)[1].numpy()\n","    #########################################################################\n","    #                       END OF YOUR CODE                                #\n","    #########################################################################\n","    return y_pred\n","   "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"IGqVw4U3Sy21"},"outputs":[],"source":["## Read DATA\n","def load_pickle(f):\n","    version = platform.python_version_tuple()\n","    if version[0] == '2':\n","        return  pickle.load(f)\n","    elif version[0] == '3':\n","        return  pickle.load(f, encoding='latin1')\n","    raise ValueError(\"invalid python version: {}\".format(version))\n","\n","def load_CIFAR_batch(filename):\n","  \"\"\" load single batch of cifar \"\"\"\n","  with open(filename, 'rb') as f:\n","    datadict = load_pickle(f)\n","    X = datadict['data']\n","    Y = datadict['labels']\n","    X = X.reshape(10000, 3, 32, 32).astype(\"float\")\n","    Y = np.array(Y)\n","    return X, Y\n","test_filename = path\n","X,Y = load_CIFAR_batch(test_filename)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"qiRBbv7fR-DB"},"outputs":[{"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for ConvNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\". \n\tUnexpected key(s) in state_dict: \"conv_1.weight\", \"conv_1.bias\", \"conv_2.weight\", \"conv_2.bias\", \"conv_3.weight\", \"conv_3.bias\", \"conv_4.weight\", \"conv_4.bias\", \"conv_5.weight\", \"conv_5.bias\", \"conv_6.weight\", \"conv_6.bias\". ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn [37], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run Prediction and Evaluation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./CNN_Classifier_7.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m prediction_cnn \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_usingCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pytorch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m acc_cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(prediction_cnn \u001b[38;5;241m==\u001b[39m Y)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_pytorch)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Accuracy= \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(acc_cnn))\n","Cell \u001b[0;32mIn [31], line 12\u001b[0m, in \u001b[0;36mpredict_usingCNN\u001b[0;34m(X, model_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_usingCNN\u001b[39m(X,model_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#########################################################################\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# TODO:                                                                 #\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# value                                                                 #\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#########################################################################\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     net \u001b[38;5;241m=\u001b[39m ConvNet()\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(X)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#########################################################################\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#                       END OF YOUR CODE                                #\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#########################################################################\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\". \n\tUnexpected key(s) in state_dict: \"conv_1.weight\", \"conv_1.bias\", \"conv_2.weight\", \"conv_2.bias\", \"conv_3.weight\", \"conv_3.bias\", \"conv_4.weight\", \"conv_4.bias\", \"conv_5.weight\", \"conv_5.bias\", \"conv_6.weight\", \"conv_6.bias\". "]}],"source":["# Data Manipulation\n","mean_pytorch = np.array([0.4914, 0.4822, 0.4465])\n","std_pytorch = np.array([0.2023, 0.1994, 0.2010])\n","X_pytorch = np.divide(np.subtract( X/255 , mean_pytorch[np.newaxis, :,np.newaxis,np.newaxis]), std_pytorch[np.newaxis, :,np.newaxis,np.newaxis])\n","\n","# Run Prediction and Evaluation\n","model_path = \"./CNN_Classifier_7.ckpt\"\n","prediction_cnn = predict_usingCNN(torch.from_numpy(X_pytorch).float(),model_path)\n","acc_cnn = sum(prediction_cnn == Y)/len(X_pytorch)\n","print(\"CNN Accuracy= %f\"%(acc_cnn))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNV/YURRLTgyD62qxCvzW0s","collapsed_sections":[],"name":"Evaluator.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
